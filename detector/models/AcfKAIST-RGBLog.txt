---------------------------------------------------------------------------
Training stage 0
Sampled 1537 windows from 2500 images.
Done sampling windows (time=253s).
Computing lambdas... done (time=15s).
Extracting features... done (time=2s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=28s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak= 32 nFtrs=1280 pos=3074 neg=5000
 i=  16 alpha=0.289 err=0.360 loss=2.56e-01
 i=  32 alpha=0.240 err=0.382 loss=1.49e-01
Done training err=0.0356 fp=0.0332 fn=0.0381 (t=0.2s).
Done training stage 0 (time=302s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 256 images.
Done sampling windows (time=60s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak=128 nFtrs=1280 pos=3074 neg=10000
 i=  16 alpha=0.155 err=0.423 loss=6.21e-01
 i=  32 alpha=0.150 err=0.426 loss=4.96e-01
 i=  48 alpha=0.115 err=0.443 loss=4.21e-01
 i=  64 alpha=0.120 err=0.440 loss=3.62e-01
 i=  80 alpha=0.138 err=0.432 loss=3.15e-01
 i=  96 alpha=0.124 err=0.438 loss=2.77e-01
 i= 112 alpha=0.110 err=0.445 loss=2.45e-01
 i= 128 alpha=0.133 err=0.434 loss=2.16e-01
Done training err=0.0444 fp=0.0547 fn=0.0342 (t=0.6s).
Done training stage 1 (time=65s).
---------------------------------------------------------------------------
Training stage 2
Sampled 5000 windows from 256 images.
Done sampling windows (time=50s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak=512 nFtrs=1280 pos=3074 neg=10000
 i=  16 alpha=0.127 err=0.437 loss=7.28e-01
 i=  32 alpha=0.121 err=0.440 loss=6.38e-01
 i=  48 alpha=0.120 err=0.440 loss=5.74e-01
 i=  64 alpha=0.112 err=0.444 loss=5.23e-01
 i=  80 alpha=0.109 err=0.445 loss=4.75e-01
 i=  96 alpha=0.117 err=0.442 loss=4.30e-01
 i= 112 alpha=0.110 err=0.445 loss=3.95e-01
 i= 128 alpha=0.099 err=0.451 loss=3.63e-01
 i= 144 alpha=0.104 err=0.448 loss=3.37e-01
 i= 160 alpha=0.087 err=0.456 loss=3.14e-01
 i= 176 alpha=0.090 err=0.455 loss=2.90e-01
 i= 192 alpha=0.092 err=0.454 loss=2.67e-01
 i= 208 alpha=0.120 err=0.440 loss=2.46e-01
 i= 224 alpha=0.106 err=0.447 loss=2.27e-01
 i= 240 alpha=0.084 err=0.458 loss=2.12e-01
 i= 256 alpha=0.113 err=0.444 loss=1.97e-01
 i= 272 alpha=0.104 err=0.448 loss=1.83e-01
 i= 288 alpha=0.104 err=0.448 loss=1.69e-01
 i= 304 alpha=0.097 err=0.452 loss=1.57e-01
 i= 320 alpha=0.085 err=0.457 loss=1.46e-01
 i= 336 alpha=0.106 err=0.447 loss=1.35e-01
 i= 352 alpha=0.096 err=0.452 loss=1.25e-01
 i= 368 alpha=0.089 err=0.456 loss=1.16e-01
 i= 384 alpha=0.094 err=0.453 loss=1.08e-01
 i= 400 alpha=0.091 err=0.455 loss=1.01e-01
 i= 416 alpha=0.102 err=0.449 loss=9.33e-02
 i= 432 alpha=0.089 err=0.456 loss=8.74e-02
 i= 448 alpha=0.092 err=0.454 loss=8.14e-02
 i= 464 alpha=0.096 err=0.452 loss=7.62e-02
 i= 480 alpha=0.088 err=0.456 loss=7.14e-02
 i= 496 alpha=0.088 err=0.456 loss=6.66e-02
 i= 512 alpha=0.081 err=0.460 loss=6.23e-02
Done training err=0.0008 fp=0.0017 fn=0.0000 (t=2.1s).
Done training stage 2 (time=56s).
---------------------------------------------------------------------------
Training stage 3
Sampled 5000 windows from 256 images.
Done sampling windows (time=47s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak=2048 nFtrs=1280 pos=3074 neg=10000
 i=  16 alpha=0.129 err=0.436 loss=7.74e-01
 i=  32 alpha=0.127 err=0.437 loss=6.88e-01
 i=  48 alpha=0.101 err=0.450 loss=6.27e-01
 i=  64 alpha=0.091 err=0.454 loss=5.82e-01
 i=  80 alpha=0.083 err=0.459 loss=5.41e-01
 i=  96 alpha=0.095 err=0.453 loss=5.05e-01
 i= 112 alpha=0.085 err=0.458 loss=4.74e-01
 i= 128 alpha=0.084 err=0.458 loss=4.44e-01
 i= 144 alpha=0.091 err=0.454 loss=4.17e-01
 i= 160 alpha=0.080 err=0.460 loss=3.92e-01
 i= 176 alpha=0.084 err=0.458 loss=3.68e-01
 i= 192 alpha=0.092 err=0.454 loss=3.46e-01
 i= 208 alpha=0.100 err=0.450 loss=3.25e-01
 i= 224 alpha=0.081 err=0.459 loss=3.04e-01
 i= 240 alpha=0.089 err=0.456 loss=2.87e-01
 i= 256 alpha=0.088 err=0.456 loss=2.70e-01
 i= 272 alpha=0.096 err=0.452 loss=2.54e-01
 i= 288 alpha=0.089 err=0.456 loss=2.38e-01
 i= 304 alpha=0.080 err=0.460 loss=2.24e-01
 i= 320 alpha=0.088 err=0.456 loss=2.10e-01
 i= 336 alpha=0.083 err=0.458 loss=1.98e-01
 i= 352 alpha=0.088 err=0.456 loss=1.86e-01
 i= 368 alpha=0.085 err=0.458 loss=1.75e-01
 i= 384 alpha=0.085 err=0.458 loss=1.65e-01
 i= 400 alpha=0.078 err=0.461 loss=1.56e-01
 i= 416 alpha=0.085 err=0.457 loss=1.47e-01
 i= 432 alpha=0.080 err=0.460 loss=1.39e-01
 i= 448 alpha=0.087 err=0.456 loss=1.31e-01
 i= 464 alpha=0.076 err=0.462 loss=1.25e-01
 i= 480 alpha=0.084 err=0.458 loss=1.18e-01
 i= 496 alpha=0.086 err=0.457 loss=1.11e-01
 i= 512 alpha=0.086 err=0.457 loss=1.05e-01
 i= 528 alpha=0.090 err=0.455 loss=9.87e-02
 i= 544 alpha=0.092 err=0.454 loss=9.31e-02
 i= 560 alpha=0.084 err=0.458 loss=8.79e-02
 i= 576 alpha=0.075 err=0.463 loss=8.29e-02
 i= 592 alpha=0.078 err=0.461 loss=7.89e-02
 i= 608 alpha=0.076 err=0.462 loss=7.49e-02
 i= 624 alpha=0.080 err=0.460 loss=7.07e-02
 i= 640 alpha=0.101 err=0.450 loss=6.66e-02
 i= 656 alpha=0.083 err=0.459 loss=6.29e-02
 i= 672 alpha=0.082 err=0.459 loss=5.91e-02
 i= 688 alpha=0.085 err=0.457 loss=5.55e-02
 i= 704 alpha=0.078 err=0.461 loss=5.22e-02
 i= 720 alpha=0.078 err=0.461 loss=4.94e-02
 i= 736 alpha=0.079 err=0.460 loss=4.69e-02
 i= 752 alpha=0.087 err=0.457 loss=4.44e-02
 i= 768 alpha=0.088 err=0.456 loss=4.18e-02
 i= 784 alpha=0.092 err=0.454 loss=3.96e-02
 i= 800 alpha=0.081 err=0.460 loss=3.76e-02
 i= 816 alpha=0.086 err=0.457 loss=3.55e-02
 i= 832 alpha=0.093 err=0.454 loss=3.35e-02
 i= 848 alpha=0.081 err=0.460 loss=3.16e-02
 i= 864 alpha=0.094 err=0.453 loss=2.98e-02
 i= 880 alpha=0.085 err=0.457 loss=2.83e-02
 i= 896 alpha=0.078 err=0.461 loss=2.67e-02
 i= 912 alpha=0.085 err=0.458 loss=2.52e-02
 i= 928 alpha=0.100 err=0.450 loss=2.37e-02
 i= 944 alpha=0.091 err=0.455 loss=2.24e-02
 i= 960 alpha=0.101 err=0.450 loss=2.12e-02
 i= 976 alpha=0.095 err=0.453 loss=2.00e-02
 i= 992 alpha=0.083 err=0.459 loss=1.89e-02
 i=1008 alpha=0.095 err=0.453 loss=1.79e-02
 i=1024 alpha=0.089 err=0.456 loss=1.70e-02
 i=1040 alpha=0.096 err=0.452 loss=1.60e-02
 i=1056 alpha=0.083 err=0.459 loss=1.52e-02
 i=1072 alpha=0.082 err=0.459 loss=1.43e-02
 i=1088 alpha=0.086 err=0.457 loss=1.36e-02
 i=1104 alpha=0.088 err=0.456 loss=1.28e-02
 i=1120 alpha=0.082 err=0.459 loss=1.21e-02
 i=1136 alpha=0.069 err=0.465 loss=1.15e-02
 i=1152 alpha=0.077 err=0.461 loss=1.09e-02
 i=1168 alpha=0.071 err=0.464 loss=1.03e-02
 i=1184 alpha=0.088 err=0.456 loss=9.72e-03
 i=1200 alpha=0.089 err=0.456 loss=9.15e-03
 i=1216 alpha=0.089 err=0.455 loss=8.64e-03
 i=1232 alpha=0.085 err=0.458 loss=8.15e-03
 i=1248 alpha=0.087 err=0.457 loss=7.68e-03
 i=1264 alpha=0.092 err=0.454 loss=7.30e-03
 i=1280 alpha=0.083 err=0.459 loss=6.92e-03
 i=1296 alpha=0.078 err=0.461 loss=6.51e-03
 i=1312 alpha=0.090 err=0.455 loss=6.15e-03
 i=1328 alpha=0.075 err=0.463 loss=5.80e-03
 i=1344 alpha=0.078 err=0.461 loss=5.51e-03
 i=1360 alpha=0.088 err=0.456 loss=5.21e-03
 i=1376 alpha=0.082 err=0.459 loss=4.93e-03
 i=1392 alpha=0.092 err=0.454 loss=4.66e-03
 i=1408 alpha=0.079 err=0.460 loss=4.40e-03
 i=1424 alpha=0.093 err=0.454 loss=4.15e-03
 i=1440 alpha=0.086 err=0.457 loss=3.93e-03
 i=1456 alpha=0.080 err=0.460 loss=3.73e-03
 i=1472 alpha=0.087 err=0.457 loss=3.53e-03
 i=1488 alpha=0.096 err=0.452 loss=3.35e-03
 i=1504 alpha=0.102 err=0.449 loss=3.16e-03
 i=1520 alpha=0.094 err=0.453 loss=2.98e-03
 i=1536 alpha=0.093 err=0.454 loss=2.82e-03
 i=1552 alpha=0.093 err=0.454 loss=2.66e-03
 i=1568 alpha=0.088 err=0.456 loss=2.52e-03
 i=1584 alpha=0.079 err=0.461 loss=2.37e-03
 i=1600 alpha=0.087 err=0.456 loss=2.24e-03
 i=1616 alpha=0.088 err=0.456 loss=2.13e-03
 i=1632 alpha=0.079 err=0.461 loss=2.03e-03
 i=1648 alpha=0.089 err=0.456 loss=1.92e-03
 i=1664 alpha=0.091 err=0.455 loss=1.82e-03
 i=1680 alpha=0.081 err=0.460 loss=1.72e-03
 i=1696 alpha=0.087 err=0.456 loss=1.62e-03
 i=1712 alpha=0.079 err=0.461 loss=1.54e-03
 i=1728 alpha=0.072 err=0.464 loss=1.45e-03
 i=1744 alpha=0.081 err=0.460 loss=1.38e-03
 i=1760 alpha=0.074 err=0.463 loss=1.31e-03
 i=1776 alpha=0.092 err=0.454 loss=1.24e-03
 i=1792 alpha=0.079 err=0.461 loss=1.17e-03
 i=1808 alpha=0.078 err=0.461 loss=1.11e-03
 i=1824 alpha=0.076 err=0.462 loss=1.06e-03
 i=1840 alpha=0.086 err=0.457 loss=1.01e-03
 i=1856 alpha=0.076 err=0.462 loss=9.58e-04
 i=1872 alpha=0.069 err=0.466 loss=9.06e-04
 i=1888 alpha=0.078 err=0.461 loss=8.54e-04
 i=1904 alpha=0.084 err=0.458 loss=8.07e-04
 i=1920 alpha=0.076 err=0.462 loss=7.64e-04
 i=1936 alpha=0.091 err=0.455 loss=7.22e-04
 i=1952 alpha=0.076 err=0.462 loss=6.83e-04
 i=1968 alpha=0.102 err=0.449 loss=6.43e-04
 i=1984 alpha=0.079 err=0.461 loss=6.06e-04
 i=2000 alpha=0.092 err=0.454 loss=5.73e-04
 i=2016 alpha=0.085 err=0.458 loss=5.44e-04
 i=2032 alpha=0.090 err=0.455 loss=5.14e-04
 i=2048 alpha=0.076 err=0.462 loss=4.87e-04
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=8.7s).
Done training stage 3 (time=59s).
---------------------------------------------------------------------------
Done training (time=482s).
