---------------------------------------------------------------------------
Training stage 0
Sampled 1537 windows from 2500 images.
Done sampling windows (time=253s).
Computing lambdas... done (time=37s).
Extracting features... done (time=8s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=28s).
Extracting features... done (time=12s).
Training AdaBoost: nWeak= 32 nFtrs=5632 pos=3074 neg=5000
 i=  16 alpha=0.517 err=0.262 loss=5.28e-02
 i=  32 alpha=0.523 err=0.260 loss=6.98e-03
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=0.5s).
Done training stage 0 (time=339s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 256 images.
Done sampling windows (time=77s).
Extracting features... done (time=13s).
Training AdaBoost: nWeak=128 nFtrs=5632 pos=3074 neg=10000
 i=  16 alpha=0.305 err=0.352 loss=3.62e-01
 i=  32 alpha=0.251 err=0.377 loss=2.22e-01
 i=  48 alpha=0.258 err=0.374 loss=1.43e-01
 i=  64 alpha=0.221 err=0.391 loss=9.61e-02
 i=  80 alpha=0.266 err=0.370 loss=6.40e-02
 i=  96 alpha=0.226 err=0.389 loss=4.41e-02
 i= 112 alpha=0.220 err=0.392 loss=3.04e-02
 i= 128 alpha=0.215 err=0.394 loss=2.12e-02
Done training err=0.0006 fp=0.0012 fn=0.0000 (t=1.6s).
Done training stage 1 (time=92s).
---------------------------------------------------------------------------
Training stage 2
Sampled 5000 windows from 384 images.
Done sampling windows (time=92s).
Extracting features... done (time=13s).
Training AdaBoost: nWeak=512 nFtrs=5632 pos=3074 neg=10000
 i=  16 alpha=0.223 err=0.390 loss=5.18e-01
 i=  32 alpha=0.179 err=0.411 loss=3.70e-01
 i=  48 alpha=0.183 err=0.410 loss=2.84e-01
 i=  64 alpha=0.190 err=0.406 loss=2.17e-01
 i=  80 alpha=0.156 err=0.423 loss=1.71e-01
 i=  96 alpha=0.176 err=0.413 loss=1.35e-01
 i= 112 alpha=0.175 err=0.413 loss=1.07e-01
 i= 128 alpha=0.177 err=0.413 loss=8.47e-02
 i= 144 alpha=0.169 err=0.416 loss=6.74e-02
 i= 160 alpha=0.176 err=0.413 loss=5.32e-02
 i= 176 alpha=0.170 err=0.416 loss=4.22e-02
 i= 192 alpha=0.178 err=0.412 loss=3.36e-02
 i= 208 alpha=0.157 err=0.422 loss=2.72e-02
 i= 224 alpha=0.145 err=0.428 loss=2.17e-02
 i= 240 alpha=0.154 err=0.424 loss=1.75e-02
 i= 256 alpha=0.165 err=0.418 loss=1.40e-02
 i= 272 alpha=0.180 err=0.411 loss=1.12e-02
 i= 288 alpha=0.158 err=0.422 loss=8.96e-03
 i= 304 alpha=0.172 err=0.415 loss=7.14e-03
 i= 320 alpha=0.177 err=0.412 loss=5.75e-03
 i= 336 alpha=0.160 err=0.420 loss=4.63e-03
 i= 352 alpha=0.158 err=0.421 loss=3.72e-03
 i= 368 alpha=0.166 err=0.418 loss=3.03e-03
 i= 384 alpha=0.159 err=0.421 loss=2.44e-03
 i= 400 alpha=0.157 err=0.422 loss=1.98e-03
 i= 416 alpha=0.159 err=0.421 loss=1.57e-03
 i= 432 alpha=0.152 err=0.424 loss=1.29e-03
 i= 448 alpha=0.154 err=0.423 loss=1.04e-03
 i= 464 alpha=0.163 err=0.419 loss=8.40e-04
 i= 480 alpha=0.169 err=0.416 loss=6.71e-04
 i= 496 alpha=0.148 err=0.426 loss=5.42e-04
 i= 512 alpha=0.174 err=0.414 loss=4.38e-04
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=4.6s).
Done training stage 2 (time=110s).
---------------------------------------------------------------------------
Training stage 3
Sampled 5000 windows from 448 images.
Done sampling windows (time=106s).
Extracting features... done (time=13s).
Training AdaBoost: nWeak=2048 nFtrs=5632 pos=3074 neg=10000
 i=  16 alpha=0.193 err=0.405 loss=5.71e-01
 i=  32 alpha=0.149 err=0.426 loss=4.47e-01
 i=  48 alpha=0.151 err=0.425 loss=3.56e-01
 i=  64 alpha=0.145 err=0.428 loss=2.92e-01
 i=  80 alpha=0.153 err=0.424 loss=2.42e-01
 i=  96 alpha=0.156 err=0.422 loss=2.02e-01
 i= 112 alpha=0.167 err=0.417 loss=1.69e-01
 i= 128 alpha=0.167 err=0.418 loss=1.40e-01
 i= 144 alpha=0.147 err=0.427 loss=1.17e-01
 i= 160 alpha=0.154 err=0.424 loss=9.88e-02
 i= 176 alpha=0.146 err=0.428 loss=8.31e-02
 i= 192 alpha=0.144 err=0.429 loss=7.02e-02
 i= 208 alpha=0.141 err=0.430 loss=5.92e-02
 i= 224 alpha=0.146 err=0.427 loss=4.97e-02
 i= 240 alpha=0.149 err=0.426 loss=4.15e-02
 i= 256 alpha=0.131 err=0.435 loss=3.49e-02
 i= 272 alpha=0.155 err=0.423 loss=2.94e-02
 i= 288 alpha=0.135 err=0.433 loss=2.51e-02
 i= 304 alpha=0.138 err=0.431 loss=2.12e-02
 i= 320 alpha=0.129 err=0.436 loss=1.80e-02
 i= 336 alpha=0.147 err=0.427 loss=1.52e-02
 i= 352 alpha=0.151 err=0.425 loss=1.28e-02
 i= 368 alpha=0.131 err=0.435 loss=1.09e-02
 i= 384 alpha=0.135 err=0.433 loss=9.29e-03
 i= 400 alpha=0.176 err=0.413 loss=7.87e-03
 i= 416 alpha=0.138 err=0.432 loss=6.69e-03
 i= 432 alpha=0.139 err=0.431 loss=5.69e-03
 i= 448 alpha=0.141 err=0.430 loss=4.81e-03
 i= 464 alpha=0.172 err=0.415 loss=4.02e-03
 i= 480 alpha=0.157 err=0.422 loss=3.38e-03
 i= 496 alpha=0.131 err=0.435 loss=2.86e-03
 i= 512 alpha=0.157 err=0.422 loss=2.39e-03
 i= 528 alpha=0.140 err=0.431 loss=2.02e-03
 i= 544 alpha=0.145 err=0.428 loss=1.70e-03
 i= 560 alpha=0.136 err=0.433 loss=1.44e-03
 i= 576 alpha=0.154 err=0.424 loss=1.21e-03
 i= 592 alpha=0.135 err=0.433 loss=1.03e-03
 i= 608 alpha=0.141 err=0.430 loss=8.72e-04
 i= 624 alpha=0.146 err=0.428 loss=7.38e-04
 i= 640 alpha=0.159 err=0.421 loss=6.17e-04
 i= 656 alpha=0.144 err=0.429 loss=5.20e-04
 i= 672 alpha=0.137 err=0.432 loss=4.44e-04
 i= 688 alpha=0.149 err=0.426 loss=3.77e-04
 i= 704 alpha=0.156 err=0.423 loss=3.17e-04
 i= 720 alpha=0.141 err=0.430 loss=2.65e-04
 i= 736 alpha=0.169 err=0.416 loss=2.24e-04
 i= 752 alpha=0.139 err=0.431 loss=1.91e-04
 i= 768 alpha=0.141 err=0.430 loss=1.60e-04
 i= 784 alpha=0.162 err=0.420 loss=1.35e-04
 i= 800 alpha=0.123 err=0.439 loss=1.16e-04
 i= 816 alpha=0.153 err=0.424 loss=9.73e-05
 i= 832 alpha=0.150 err=0.426 loss=8.25e-05
 i= 848 alpha=0.144 err=0.428 loss=6.93e-05
 i= 864 alpha=0.146 err=0.427 loss=5.85e-05
 i= 880 alpha=0.159 err=0.421 loss=4.90e-05
 i= 896 alpha=0.149 err=0.426 loss=4.13e-05
 i= 912 alpha=0.140 err=0.430 loss=3.47e-05
 i= 928 alpha=0.146 err=0.427 loss=2.92e-05
 i= 944 alpha=0.148 err=0.427 loss=2.48e-05
 i= 960 alpha=0.142 err=0.430 loss=2.09e-05
 i= 976 alpha=0.151 err=0.425 loss=1.75e-05
 i= 992 alpha=0.154 err=0.424 loss=1.47e-05
 i=1008 alpha=0.162 err=0.420 loss=1.24e-05
 i=1024 alpha=0.149 err=0.426 loss=1.05e-05
 i=1040 alpha=0.142 err=0.429 loss=8.83e-06
 i=1056 alpha=0.145 err=0.428 loss=7.48e-06
 i=1072 alpha=0.150 err=0.425 loss=6.37e-06
 i=1088 alpha=0.139 err=0.431 loss=5.44e-06
 i=1104 alpha=0.151 err=0.425 loss=4.63e-06
 i=1120 alpha=0.152 err=0.425 loss=3.92e-06
 i=1136 alpha=0.139 err=0.431 loss=3.30e-06
 i=1152 alpha=0.150 err=0.426 loss=2.77e-06
 i=1168 alpha=0.139 err=0.431 loss=2.35e-06
 i=1184 alpha=0.136 err=0.432 loss=2.00e-06
 i=1200 alpha=0.148 err=0.427 loss=1.69e-06
 i=1216 alpha=0.142 err=0.430 loss=1.43e-06
 i=1232 alpha=0.140 err=0.430 loss=1.22e-06
 i=1248 alpha=0.133 err=0.434 loss=1.04e-06
 i=1264 alpha=0.127 err=0.437 loss=8.87e-07
 i=1280 alpha=0.142 err=0.430 loss=7.47e-07
 i=1296 alpha=0.146 err=0.428 loss=6.35e-07
 i=1312 alpha=0.134 err=0.433 loss=5.44e-07
 i=1328 alpha=0.153 err=0.424 loss=4.64e-07
 i=1344 alpha=0.137 err=0.432 loss=3.91e-07
 i=1360 alpha=0.146 err=0.427 loss=3.31e-07
 i=1376 alpha=0.145 err=0.428 loss=2.77e-07
 i=1392 alpha=0.128 err=0.436 loss=2.34e-07
 i=1408 alpha=0.146 err=0.428 loss=2.00e-07
 i=1424 alpha=0.143 err=0.429 loss=1.70e-07
 i=1440 alpha=0.141 err=0.430 loss=1.44e-07
 i=1456 alpha=0.135 err=0.433 loss=1.23e-07
 i=1472 alpha=0.163 err=0.419 loss=1.04e-07
 i=1488 alpha=0.140 err=0.431 loss=8.82e-08
 i=1504 alpha=0.142 err=0.430 loss=7.42e-08
 i=1520 alpha=0.144 err=0.429 loss=6.25e-08
 i=1536 alpha=0.137 err=0.432 loss=5.32e-08
 i=1552 alpha=0.143 err=0.429 loss=4.53e-08
 i=1568 alpha=0.131 err=0.435 loss=3.86e-08
 i=1584 alpha=0.137 err=0.432 loss=3.26e-08
 i=1600 alpha=0.139 err=0.431 loss=2.77e-08
 i=1616 alpha=0.148 err=0.426 loss=2.34e-08
 i=1632 alpha=0.150 err=0.426 loss=1.97e-08
 i=1648 alpha=0.142 err=0.430 loss=1.67e-08
 i=1664 alpha=0.144 err=0.428 loss=1.41e-08
 i=1680 alpha=0.137 err=0.432 loss=1.20e-08
 i=1696 alpha=0.146 err=0.428 loss=1.02e-08
 i=1712 alpha=0.150 err=0.426 loss=8.55e-09
 i=1728 alpha=0.137 err=0.432 loss=7.25e-09
 i=1744 alpha=0.138 err=0.431 loss=6.16e-09
 i=1760 alpha=0.143 err=0.429 loss=5.25e-09
 i=1776 alpha=0.151 err=0.425 loss=4.43e-09
 i=1792 alpha=0.149 err=0.426 loss=3.75e-09
 i=1808 alpha=0.150 err=0.425 loss=3.18e-09
 i=1824 alpha=0.145 err=0.428 loss=2.71e-09
 i=1840 alpha=0.127 err=0.437 loss=2.29e-09
 i=1856 alpha=0.118 err=0.441 loss=1.98e-09
 i=1872 alpha=0.144 err=0.429 loss=1.67e-09
 i=1888 alpha=0.146 err=0.427 loss=1.42e-09
 i=1904 alpha=0.151 err=0.425 loss=1.21e-09
 i=1920 alpha=0.147 err=0.427 loss=1.03e-09
 i=1936 alpha=0.139 err=0.431 loss=8.72e-10
 i=1952 alpha=0.129 err=0.436 loss=7.43e-10
 i=1968 alpha=0.134 err=0.433 loss=6.30e-10
 i=1984 alpha=0.149 err=0.426 loss=5.40e-10
 i=2000 alpha=0.158 err=0.422 loss=4.56e-10
 i=2016 alpha=0.142 err=0.429 loss=3.88e-10
 i=2032 alpha=0.134 err=0.434 loss=3.32e-10
 i=2048 alpha=0.144 err=0.428 loss=2.79e-10
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=16.0s).
Done training stage 3 (time=136s).
---------------------------------------------------------------------------
Done training (time=677s).
